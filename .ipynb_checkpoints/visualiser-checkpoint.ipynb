{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # don't show all the tensorflow startup messages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "from sys import path\n",
    "import h5py\n",
    "\n",
    "import json\n",
    "import cv2\n",
    "path.append(f'{os.getcwd()}/training')\n",
    "path.append(f'{os.getcwd()}/utils')\n",
    "path.append(f'{os.getcwd()}/noiseprint2')\n",
    "from dct_train import main as train\n",
    "from preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input:\n",
    "    def __init__(self, downscale_factor, grayscale, dct_rep, patch_size, bands, sf_lo, sf_mid, sf_hi, his_range):\n",
    "        self.downscale_factor = downscale_factor\n",
    "        self.colour_space = self.get_colour_space(grayscale)\n",
    "        self.dct_rep = dct_rep\n",
    "        self.patch_size = patch_size\n",
    "        self.bands = bands\n",
    "        self.sf_range = [sf_lo, sf_mid, sf_hi]\n",
    "        self.his_range = his_range\n",
    "\n",
    "        self.sf_num = self.num_of_sf()\n",
    "        self.dset_name = self.get_dset_name(grayscale)\n",
    "        self.his_size = self.get_his_range()\n",
    "\n",
    "    def num_of_sf(self):\n",
    "        if self.bands == 3:\n",
    "            return sum([sf[1] - sf[0] for sf in self.sf_range])\n",
    "        else:\n",
    "            return self.sf_range[self.bands][1] - self.sf_range[self.bands][0]\n",
    "       \n",
    "    def get_dset_name(self, grayscale):\n",
    "        return f'g:{grayscale}p:{self.patch_size}_his:{self.his_range[0]},{self.his_range[1]}_sf_num:{self.sf_num}_subbands:{self.bands}'\n",
    "\n",
    "    def get_colour_space(self, grayscale):\n",
    "        return cv2.COLOR_BGR2GRAY if grayscale else cv2.COLOR_BGR2RGB\n",
    "\n",
    "    def get_his_range(self):\n",
    "        return (len(range(self.his_range[0], self.his_range[1])) + 1) * self.sf_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length for the dataset, used for generator function and to calculate steps_per_epoch\n",
    "def get_dset_len(path, dset):\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        return f[dset].shape[0]\n",
    "\n",
    "\n",
    "# generator function\n",
    "def generator(dataset_name, batch_size, num_examples):\n",
    "    with h5py.File(f'processed/DCT_test_{dataset_name}.h5', 'r') as f:\n",
    "        X = f['DCT']\n",
    "        while True:\n",
    "            for i in range(0, num_examples, batch_size):\n",
    "                batch_X = X[i: min(i + batch_size, num_examples)]\n",
    "                yield (batch_X)\n",
    "\n",
    "\n",
    "def get_labels(dataset_name):\n",
    "    with h5py.File(f'processed/labels_test_{dataset_name}.h5', 'r') as f:\n",
    "        return np.array(f['labels'][()])\n",
    "\n",
    "\n",
    "# get predictions and convert numerical values to class name\n",
    "def get_predictions(dataset_name, model, num_examples):\n",
    "    predictions = np.argmax(model.predict(\n",
    "        generator(dataset_name, 32, num_examples), steps=np.ceil(num_examples/32)), axis=1)\n",
    "\n",
    "    return np.select(\n",
    "        [\n",
    "            predictions == 0,\n",
    "            predictions == 1,\n",
    "            predictions == 2,\n",
    "            predictions == 3,\n",
    "            predictions == 4,\n",
    "            predictions == 5,\n",
    "            predictions == 6,\n",
    "            predictions == 7,\n",
    "\n",
    "        ],\n",
    "        [\n",
    "            'facebook',\n",
    "            'flickr',\n",
    "            'google+',\n",
    "            'instagram',\n",
    "            'original',\n",
    "            'telegram',\n",
    "            'twitter',\n",
    "            'whatsapp'\n",
    "        ],\n",
    "        predictions\n",
    "    )\n",
    "\n",
    "\n",
    "# get accuracy at patch level\n",
    "def patch_truth(labels, predictions, classes):\n",
    "\n",
    "    patch_truth = [label.decode('UTF-8').split('.')[0] for label in labels]\n",
    "\n",
    "    print(classification_report(patch_truth, predictions, target_names=classes))\n",
    "\n",
    "\n",
    "# get accuracy at image level\n",
    "def image_truth(labels, predictions, classes):\n",
    "    # decode\n",
    "    y_test_im = []\n",
    "    for y in labels:\n",
    "        y_test_im.append(y.decode('UTF-8'))\n",
    "\n",
    "    df = pd.DataFrame([y_test_im, predictions],\n",
    "                      index=['truth', 'prediction']).T\n",
    "\n",
    "    # group by class and image number\n",
    "    grouped_df = df.groupby('truth', as_index=False)[\n",
    "        'prediction'].agg(pd.Series.mode)\n",
    "    # print(grouped_df.to_string())\n",
    "\n",
    "    # split into respective image number\n",
    "    grouped_df['truth'] = grouped_df['truth'].str.split('.').str[0]\n",
    "    \n",
    "    # get rid of non string values\n",
    "    grouped_df = grouped_df[grouped_df['prediction'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "    image_truth = grouped_df['truth'].tolist()\n",
    "    image_predictions = grouped_df['prediction'].tolist()\n",
    "\n",
    "   \n",
    "    print(classification_report(image_truth, image_predictions, target_names=classes))\n",
    "    \n",
    "def main(name, dataset_name):\n",
    "    # user defined variables\n",
    "\n",
    "    model = models.load_model(f'models/cnn_{name}')\n",
    "\n",
    "    classes = ['facebook', 'flickr', 'google+', 'instagram',\n",
    "               'original', 'telegram', 'twitter', 'whatsapp']\n",
    "\n",
    "    # get the number of examples for the generator and steps\n",
    "    num_examples = get_dset_len(f'{path[0]}/processed/DCT_test_{dataset_name}.h5', 'DCT')\n",
    "\n",
    "    # predictions represented as integer representation of classes\n",
    "    predictions = get_predictions(dataset_name, model, num_examples)\n",
    "\n",
    "    # labels with string name and image indexes\n",
    "    labels = get_labels(dataset_name)\n",
    "\n",
    "    patch_truth(labels, predictions, classes)\n",
    "\n",
    "    image_truth(labels, predictions, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run code and obtain results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as f:\n",
    "    args = json.load(f)\n",
    "\n",
    "input = Input(**args)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "architecture = 'dct_cnn_2017'\n",
    "\n",
    "name = f'{architecture}_e:{epochs}_b:{batch_size}'\n",
    "test(name, input.dset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
